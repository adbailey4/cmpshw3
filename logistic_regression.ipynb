{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################################\n",
    "# this imports all the functions in logistic regression\n",
    "# you should be able to run this cell at any time to \n",
    "# \"reload\" the functions\n",
    "########################################################\n",
    "\n",
    "from logistic_regression import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 6179)\n"
     ]
    }
   ],
   "source": [
    "########################################################\n",
    "# prepare and load the training data.  this involves\n",
    "# reading in the data and finding the best features\n",
    "########################################################\n",
    "\n",
    "# if cant find stopwords you can download using this:\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# init\n",
    "stop_words = stopwords.words('english')\n",
    "train_data = 'train.csv'\n",
    "# test_data = 'test.csv'\n",
    "\n",
    "# interpret data\n",
    "messages, text_labels = read_spam_data(train_data)\n",
    "all_train_data = create_train_data(messages, stop_words)\n",
    "int_labels = create_spam_ham_labels(text_labels, spam=1, ham=0)\n",
    "\n",
    "# get sizes\n",
    "n_messages = len(messages)\n",
    "n_features = all_train_data.shape[1]\n",
    "\n",
    "# make sure everything is still aligned\n",
    "print(all_train_data.shape)\n",
    "assert all_train_data.shape[0] == len(messages)\n",
    "assert all_train_data.shape[0] == len(int_labels)\n",
    "assert all_train_data.shape[0] == len(text_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAMBDAS:\n",
      "\tbase: 2   log_min: -18   log_max: 3\n",
      "\t[3.814697265625e-06, 7.62939453125e-06, 1.52587890625e-05, 3.0517578125e-05, 6.103515625e-05, 0.0001220703125, 0.000244140625, 0.00048828125, 0.0009765625, 0.001953125, 0.00390625, 0.0078125, 0.015625, 0.03125, 0.0625, 0.125, 0.25, 0.5, 1, 2, 4, 8]\n"
     ]
    }
   ],
   "source": [
    "########################################################\n",
    "# this is the definition of the hyper parameters for\n",
    "# the regression\n",
    "########################################################\n",
    "\n",
    "# lambda\n",
    "lambda_base = 2 #8 #np.e\n",
    "lambda_exp_min = -18 #-5\n",
    "lambda_exp_max = 3 #1\n",
    "list_of_lambdas = [lambda_base**i for i in range(lambda_exp_min,lambda_exp_max+1)] \n",
    "print(\"LAMBDAS:\\n\\tbase: {}   log_min: {}   log_max: {}\\n\\t{}\".format( \n",
    "      lambda_base, lambda_exp_min, lambda_exp_max, list_of_lambdas))\n",
    "\n",
    "# sigmoid params\n",
    "eta_0 = 0.1\n",
    "alpha = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################################\n",
    "# divide the data for 10-fold cross validation\n",
    "########################################################\n",
    "\n",
    "# identifiers\n",
    "TRAIN_DATA = \"t_data\"\n",
    "TRAIN_LABELS = \"t_labels\"\n",
    "VALIDATE_DATA = \"v_data\"\n",
    "VALIDATE_LABELS = \"v_labels\"\n",
    "\n",
    "# prep\n",
    "number_of_buckets = 10\n",
    "size_of_bucket = int(n_messages / number_of_buckets)\n",
    "all_train_buckets = dict()\n",
    "\n",
    "# divide into buckets\n",
    "idx = 0\n",
    "for b in range(number_of_buckets):\n",
    "    data = all_train_data[idx:idx+size_of_bucket]\n",
    "    labels = int_labels[idx:idx+size_of_bucket]\n",
    "    all_train_buckets[b] = [data, labels]\n",
    "    idx += size_of_bucket\n",
    "    \n",
    "    \n",
    "# how to create train and validation data sets\n",
    "def get_train_data_set(idx):\n",
    "    t_data, t_labels = list(), list()\n",
    "    v_data, v_labels = None, None\n",
    "    for k in all_train_buckets.keys():\n",
    "        v = all_train_buckets[k]\n",
    "        if k == idx:\n",
    "            v_data = v[0]\n",
    "            v_labels = v[1]\n",
    "        else:\n",
    "            t_data.append(v[0])\n",
    "            t_labels.append(v[1])\n",
    "    return {\n",
    "        TRAIN_DATA: np.vstack(t_data), \n",
    "        TRAIN_LABELS: np.hstack(t_labels),  \n",
    "        VALIDATE_DATA: v_data, \n",
    "        VALIDATE_LABELS: v_labels\n",
    "    }\n",
    "\n",
    "# get data\n",
    "all_training_datasets = [get_train_data_set(x) for x in list(range(number_of_buckets))]\n",
    "\n",
    "# validation\n",
    "assert len(all_training_datasets) == number_of_buckets\n",
    "for ds in all_training_datasets:\n",
    "    assert ds[TRAIN_DATA].shape[1] == n_features\n",
    "    assert ds[TRAIN_DATA].shape[0] == len(ds[TRAIN_LABELS])\n",
    "    assert ds[VALIDATE_DATA].shape[1] == n_features\n",
    "    assert ds[VALIDATE_DATA].shape[0] == len(ds[VALIDATE_LABELS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################################\n",
    "# definition of our regression function\n",
    "########################################################\n",
    "\n",
    "\n",
    "def run_regression(lamda, train, train_labels, validate, validate_labels, \n",
    "                   eta_0=0.1, alpha=0.9, iterations=321, verbose=False):\n",
    "    # init\n",
    "    report_frequency = int(iterations / 16.0)\n",
    "    t = None\n",
    "    \n",
    "    #run regression\n",
    "    try:\n",
    "        weights = np.random.normal(0, 0.2, n_features)\n",
    "        min_validate_loss = sys.maxsize\n",
    "        min_train_loss = sys.maxsize\n",
    "        for t in range(iterations):\n",
    "            weights = logistic_regression(train, train_labels, weights, lamda, alpha, eta_0, t)\n",
    "            train_loss = square_loss(train, train_labels, weights=weights)\n",
    "            val_loss = square_loss(validate, validate_labels, weights=weights)\n",
    "            if verbose and t % report_frequency == 0:\n",
    "                print(\"{}:\\t#{}\\ttrain {}  \\t\\tvalidate {}\".format(l, t, train_loss, val_loss))\n",
    "            if val_loss < min_validate_loss: min_validate_loss = val_loss\n",
    "            if train_loss < min_train_loss: min_train_loss = train_loss\n",
    "    except Exception as e:\n",
    "        print(\"\\nlambda {} #{}: {}\".format(l, t, e), sys.stderr)\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "    \n",
    "    # return best\n",
    "    return min_validate_loss, min_train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LAMBDA: 3.814697265625e-06\n",
      "\t.......... (229s)\n",
      "\tv errors:    [3.5647690661476017, 5.133366933702785, 4.638260301316997, 4.42305240315012, 5.178125305910893, 4.855358925247892, 3.0020119501703113, 3.394440442991451, 3.236079378458119, 2.709137728010357]\n",
      "\tv error avg: 4.013460243510653\n",
      "\tv error std: 0.882648577411582\n",
      "\n",
      "LAMBDA: 7.62939453125e-06\n",
      "\t.......... (227s)\n",
      "\tv errors:    [3.585546504000259, 5.371451538300512, 4.776087948329062, 4.382563998922925, 5.044300923684652, 4.999338961851623, 2.9361191337703416, 3.441897570871343, 3.166339721065919, 2.756380866783787]\n",
      "\tv error avg: 4.046002716758042\n",
      "\tv error std: 0.9248944722270547\n",
      "\n",
      "LAMBDA: 1.52587890625e-05\n",
      "\t.......... (229s)\n",
      "\tv errors:    [3.6411084466154615, 5.393276826301738, 4.65297205093758, 4.473483858463125, 5.0948939265882585, 4.886159765545371, 3.0469279707642256, 3.4525310343571416, 3.273920714169579, 2.6838991003385857]\n",
      "\tv error avg: 4.059917369408106\n",
      "\tv error std: 0.9020052728764745\n",
      "\n",
      "LAMBDA: 3.0517578125e-05\n",
      "\t.......... (226s)\n",
      "\tv errors:    [3.80450730209024, 5.3046327372841775, 4.632142838165642, 4.454497733866609, 5.201522635168799, 4.848285894442814, 2.8920908583743534, 3.474127268590046, 3.2881797286244634, 2.8503924764750854]\n",
      "\tv error avg: 4.075037947308223\n",
      "\tv error std: 0.8823653297166324\n",
      "\n",
      "LAMBDA: 6.103515625e-05\n",
      "\t.......... (227s)\n",
      "\tv errors:    [3.7070928421846716, 5.365854242266109, 4.775785390397127, 4.5133362485878665, 5.1887506421892216, 5.122014800024676, 2.940919744250636, 3.459679620211229, 3.2755265721990057, 2.7505656274974912]\n",
      "\tv error avg: 4.109952572980804\n",
      "\tv error std: 0.9416689549797244\n",
      "\n",
      "LAMBDA: 0.0001220703125\n",
      "\t.......... (238s)\n",
      "\tv errors:    [3.637130246745325, 5.3027426357610965, 4.64233543350755, 4.467820568134507, 5.233808938582889, 4.9388061385265685, 3.108119763660744, 3.4337072256391203, 3.3268516748989376, 2.755059409781517]\n",
      "\tv error avg: 4.084638203523825\n",
      "\tv error std: 0.8894612153824651\n",
      "\n",
      "LAMBDA: 0.000244140625\n",
      "\t.......... (227s)\n",
      "\tv errors:    [3.6392819593326906, 5.125384904355811, 4.572259862791741, 4.388978793081474, 5.1293410876888865, 4.905568192948698, 2.9392215112382614, 3.411520609998031, 3.2797097215181994, 2.7064446521220087]\n",
      "\tv error avg: 4.00977112950758\n",
      "\tv error std: 0.8737028872863108\n",
      "\n",
      "LAMBDA: 0.00048828125\n",
      "\t.......... (230s)\n",
      "\tv errors:    [3.7349969512263885, 5.366559762794542, 4.497061548153594, 4.1907493504718865, 5.145632539869479, 4.672721684640946, 3.0495474567801786, 3.4052908840568654, 3.4026986306929374, 2.6667257345325295]\n",
      "\tv error avg: 4.013198454321935\n",
      "\tv error std: 0.8588295669205007\n",
      "\n",
      "LAMBDA: 0.0009765625\n",
      "\t.......... (228s)\n",
      "\tv errors:    [3.7373091961686518, 5.360548701631997, 4.453686577296935, 4.509102330636556, 5.147605047113925, 5.0186466310835325, 3.0387155308749474, 3.4581156435772047, 3.410126415684435, 2.6834268406563977]\n",
      "\tv error avg: 4.081728291472458\n",
      "\tv error std: 0.8928595244500802\n",
      "\n",
      "LAMBDA: 0.001953125\n",
      "\t.......... (228s)\n",
      "\tv errors:    [3.8499595998995852, 5.38337917385607, 4.455793994935211, 4.455188045417915, 5.305639504363936, 4.962157311459757, 3.0984437402669593, 3.5084277726000557, 3.3870076882459896, 2.7118813827797648]\n",
      "\tv error avg: 4.111787821382524\n",
      "\tv error std: 0.8914104840420998\n",
      "\n",
      "LAMBDA: 0.00390625\n",
      "\t.......... (226s)\n",
      "\tv errors:    [3.702582880073889, 5.187708802615066, 4.476709146096178, 4.4229451252004, 5.099363898443994, 4.615353720372428, 3.1858825198393763, 3.125272347106816, 2.498866295222449, 2.68816350768888]\n",
      "\tv error avg: 3.9002848242659467\n",
      "\tv error std: 0.9378340190042074\n",
      "\n",
      "LAMBDA: 0.0078125\n",
      "\t.......... (229s)\n",
      "\tv errors:    [3.7624367060524517, 5.29891847341965, 4.544737241691533, 4.423345993860413, 5.021238462830072, 4.664198989415924, 3.3079928054873498, 3.0958709796182293, 2.667990206210403, 2.794408709327481]\n",
      "\tv error avg: 3.958113856791351\n",
      "\tv error std: 0.9060989742545632\n",
      "\n",
      "LAMBDA: 0.015625\n",
      "\t.......... (226s)\n",
      "\tv errors:    [3.4792161227861658, 4.957355040252388, 4.653261087707259, 4.482612754725995, 4.790490974360675, 4.845268316825664, 3.466996893293487, 2.840732567175809, 1.8138482492652304, 2.8664282032460413]\n",
      "\tv error avg: 3.819621020963871\n",
      "\tv error std: 1.0273089201888257\n",
      "\n",
      "LAMBDA: 0.03125\n",
      "\t.......... (227s)\n",
      "\tv errors:    [3.32793977282203, 4.779582183878417, 4.843086003605918, 4.622482150590348, 4.548384691710997, 4.9584986453946565, 3.67354167437441, 3.1668427483507204, 2.2612120756074026, 2.9560766016519393]\n",
      "\tv error avg: 3.913764654798684\n",
      "\tv error std: 0.9064577759244778\n",
      "\n",
      "LAMBDA: 0.0625\n",
      "\t.......... (226s)\n",
      "\tv errors:    [3.7564279102250535, 4.415889873498174, 5.180386407089752, 4.855234725739555, 5.105049438660006, 5.304240595726942, 3.8975413718380967, 3.620893642130614, 3.0063336205874367, 2.908632937007428]\n",
      "\tv error avg: 4.205063052250305\n",
      "\tv error std: 0.8480196835105472\n",
      "\n",
      "LAMBDA: 0.125\n",
      "\t.......... (226s)\n",
      "\tv errors:    [5.274984376285976, 5.785168653165494, 5.740399727983645, 5.154201371599136, 5.88541875159393, 5.9174712809620065, 4.109067354325974, 5.2103934338383056, 4.5837950964416745, 4.2542256171564405]\n",
      "\tv error avg: 5.191512566335258\n",
      "\tv error std: 0.6395668577810412\n",
      "\n",
      "LAMBDA: 0.25\n",
      "\t.......... (228s)\n",
      "\tv errors:    [6.926279794283174, 7.348901710042551, 6.633882272335411, 6.312155418168327, 6.704791392592113, 6.888141996270844, 5.964878283471855, 6.226541444281286, 6.039533799769124, 5.233505463899307]\n",
      "\tv error avg: 6.4278611575113995\n",
      "\tv error std: 0.5721262612931893\n",
      "\n",
      "LAMBDA: 0.5\n",
      "\t.......... (229s)\n",
      "\tv errors:    [8.712724595435272, 8.841581880548254, 8.119118790865722, 7.785009997689632, 8.207778286080373, 8.426775605431004, 7.675512655124428, 7.707421199766879, 7.627764449429632, 6.787423999147244]\n",
      "\tv error avg: 7.989111145951844\n",
      "\tv error std: 0.5745053711195092\n",
      "\n",
      "LAMBDA: 1\n",
      "\t.......... (231s)\n",
      "\tv errors:    [11.344581990543317, 11.185066750934102, 10.457291766608888, 10.059464599121366, 10.592006527570627, 10.73199833732111, 9.954735637974878, 10.013452443280544, 10.069829399414788, 9.162655630237609]\n",
      "\tv error avg: 10.35710830830072\n",
      "\tv error std: 0.6119000863758807\n",
      "\n",
      "LAMBDA: 2\n",
      "\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ucsc_projects\\classes\\cmps242\\hw2\\cmpshw3\\logistic_regression.py:140: RuntimeWarning: overflow encountered in multiply\n",
      "  new_weights = weights*(1-(eta*l)) - (eta*np.matmul(np.array(y_hat-labels), inputs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......... (229s)\n",
      "\tv errors:    [14.88604954231149, 14.510717431216971, 13.597560149389, 13.312495047096471, 14.025759953415577, 13.985770559972487, 13.172968682499796, 13.317558846048437, 13.574784611179288, 12.498583369679718]\n",
      "\tv error avg: 13.688224819280922\n",
      "\tv error std: 0.6552962804770385\n",
      "\n",
      "LAMBDA: 4\n",
      "\t.......... (226s)\n",
      "\tv errors:    [18.86795862535735, 18.269875363494254, 17.70847992783336, 17.313904045697306, 17.822863362888363, 17.86179394946371, 16.281856929305214, 17.048225218866065, 17.461189722964676, 16.184818455686056]\n",
      "\tv error avg: 17.482096560155632\n",
      "\tv error std: 0.7869705501199931\n",
      "\n",
      "LAMBDA: 8\n",
      "\t.......... (229s)\n",
      "\tv errors:    [20.603910986226968, 19.614282909690818, 17.88377771839103, 17.691438305008006, 19.617748944800663, 18.930858248160874, 16.986887460294692, 18.83498870013509, 19.86892202089999, 16.0]\n",
      "\tv error avg: 18.603281529360814\n",
      "\tv error std: 1.3621884976989045\n"
     ]
    }
   ],
   "source": [
    "########################################################\n",
    "# run on each of our k-folded datasets\n",
    "########################################################\n",
    "\n",
    "# prep\n",
    "lambda_to_validate_errors = dict()\n",
    "lambda_to_training_errors = dict()\n",
    "\n",
    "# calculate for our lambdas\n",
    "for l in list_of_lambdas:\n",
    "    start = timer()\n",
    "    print(\"\\nLAMBDA: {}\\n\\t\".format(l),end='')\n",
    "    v_errors = list()\n",
    "    t_errors = list()\n",
    "    lambda_to_validate_errors[l] = v_errors\n",
    "    lambda_to_training_errors[l] = t_errors\n",
    "    for dataset in all_training_datasets:\n",
    "        v_error, t_error = run_regression(l, dataset[TRAIN_DATA], dataset[TRAIN_LABELS], \n",
    "                       dataset[VALIDATE_DATA], dataset[VALIDATE_LABELS])\n",
    "        v_errors.append(v_error)\n",
    "        t_errors.append(t_error)\n",
    "        print('.', end='')\n",
    "    print(\" ({}s)\".format(int(timer() - start)))\n",
    "    print(\"\\tv errors:    {}\".format(v_errors))\n",
    "    print(\"\\tv error avg: {}\".format(np.mean(v_errors)))\n",
    "    print(\"\\tv error std: {}\".format(np.std(v_errors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEZCAYAAACU3p4jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f87f5ed588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "########################################################\n",
    "# analyze and print plots of the data\n",
    "########################################################\n",
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_plot_data(items):\n",
    "    items.sort(key=lambda x: x[0])\n",
    "    x, y, var, log_lambda = list(), list(), list(), lambda_exp_min\n",
    "    for k, v in items:\n",
    "        x.append(log_lambda)\n",
    "        y.append(np.mean(v))\n",
    "        var.append(np.std(v)**2)\n",
    "        assert lambda_base**log_lambda == k\n",
    "        log_lambda += 1\n",
    "    return x, y, var\n",
    "\n",
    "validate_x, validate_y, validate_v = get_plot_data(list(lambda_to_validate_errors.items()))\n",
    "train_x, train_y, train_v = get_plot_data(list(lambda_to_training_errors.items()))\n",
    "\n",
    "plt.errorbar(train_x, train_y, train_v, None, 'bo-', label=\"Train\")\n",
    "plt.errorbar(validate_x, validate_y, validate_v, None, 'ro-', label=\"Validate\")\n",
    "plt.axis([lambda_exp_min-.5, lambda_exp_max-.5, -2, 20])\n",
    "plt.legend(bbox_to_anchor=(.31,.95))\n",
    "plt.title(\"Logistic Regression Error Rates\")\n",
    "plt.xlabel(\"Log of Lambda (Base {})\".format(lambda_base))\n",
    "plt.ylabel(\"Error\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
